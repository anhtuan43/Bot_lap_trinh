from datetime import datetime
import chainlit as cl
from config import REFLECTION
from services import generate_response
from prompt import AITutorPrompt

async def start_chat():
    """Kh·ªüi t·∫°o l·ªãch s·ª≠ chat trong session."""
    msg = cl.Message(content="üíª H·ªçc l·∫≠p tr√¨nh kh√¥ng kh√≥! üöÄ M√¨nh l√† gia s∆∞ AI, gi√∫p b·∫°n ti·∫øp c·∫≠n ki·∫øn th·ª©c l·∫≠p tr√¨nh m·ªôt c√°ch d·ªÖ hi·ªÉu v√† lu√¥n s·∫µn s√†ng ƒë·ªìng h√†nh c√πng b·∫°n tr√™n h√†nh tr√¨nh kh√°m ph√° c√¥ng ngh·ªá. ü§ñ")
    await msg.send()
    cl.user_session.set("history", [])

async def handle_message(message: cl.Message):
    """
    X·ª≠ l√Ω tin nh·∫Øn ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ ph·∫£n h·ªìi t·ª´ LLM.
    
    Args:
        message (cl.Message): Tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng.
    """
    start_time = datetime.now()
    query = message.content

    # L·∫•y v√† c·∫≠p nh·∫≠t l·ªãch s·ª≠ chat
    history = cl.user_session.get("history", [])
    history.append({"role": "user", "content": query})

    # T·∫°o prompt t·ª´ l·ªãch s·ª≠ g·∫ßn nh·∫•t
    latest_history = REFLECTION(history, lastItemsConsidereds=8)
    prompt = AITutorPrompt(history=latest_history).format()

    # T·∫°o tin nh·∫Øn ƒë·ªÉ stream
    msg = cl.Message(content="")
    await msg.send()

    # G·ªçi API LLM v√† stream ph·∫£n h·ªìi
    stream = generate_response(prompt)
    response_text = ""

    for event in stream:
        if event.choices[0].text:
            response_text += event.choices[0].text
            await msg.stream_token(event.choices[0].text)

    # C·∫≠p nh·∫≠t l·ªãch s·ª≠ v·ªõi ph·∫£n h·ªìi
    history.append({"role": "Assistant", "content": response_text})
    cl.user_session.set("history", history)

    # T√≠nh th·ªùi gian x·ª≠ l√Ω v√† c·∫≠p nh·∫≠t tin nh·∫Øn
    end_time = datetime.now()
    processing_time = (end_time - start_time).total_seconds()
    final_content = f"{response_text} (‚è± {processing_time:.3f}s)"
    msg.content = final_content
    await msg.update()